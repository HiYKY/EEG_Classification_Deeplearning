{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Link to the dataset:**:[https://www.kaggle.com/harunshimanto/epileptic-seizure-recognition](https://www.kaggle.com/harunshimanto/epileptic-seizure-recognition)"},{"metadata":{"_uuid":"b9ad6f280e93376b5811f0cd1f25556150660b21"},"cell_type":"markdown","source":"# Importing the libraries"},{"metadata":{"trusted":true,"_uuid":"87d159a308dde25e6f89f58501552945f4c261cf","_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"710c7bc8e8f0ebf31b579ae609e2c8b364e4b731"},"cell_type":"markdown","source":"# Load the Dataset"},{"metadata":{"trusted":true,"_uuid":"ffb826c5e8da301b74c3a0161e7dcc079fec03ce","_kg_hide-input":true},"cell_type":"code","source":"ESR = pd.read_csv('../input/Epileptic Seizure Recognition.csv')\nESR.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f747e03448e282cdb4f5a611a8aa2191acc71c80"},"cell_type":"markdown","source":"# Read and Show Dataset\n* The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds.\n\n* The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.\n\n* We divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time.\n\n* So now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}.\n\n* The response variable is y in column 179, the Explanatory variables X1, X2, ..., X178"},{"metadata":{"trusted":true},"cell_type":"code","source":"ESR.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98727073fd4a8acefbbe53251f25fe30986f1e2f","_kg_hide-input":true},"cell_type":"code","source":"ESR.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"17c90c1ff8add7ace30bd8d2cfb1fa5cb48c0e48"},"cell_type":"code","source":"cols = ESR.columns\ntgt = ESR.y\ntgt.unique()\ntgt[tgt>1]=0\nax = sn.countplot(tgt,label=\"Count\")\nnon_seizure, seizure = tgt.value_counts()\nprint('The number of trials for the non-seizure class is:', non_seizure)\nprint('The number of trials for the seizure class is:', seizure)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b8358047321392e0f1a2fb20ca53c6668d8cdf3"},"cell_type":"markdown","source":"As we can see, there are 178 EEG features and 5 possible classes. The main goal of the dataset it's to be able to correctly identify epileptic seizures from EEG data, so a binary classification between classes of label 1 and the rest (2,3,4,5). In order to train our model, let's define our independent variables (X) and our dependent variable (y)."},{"metadata":{"trusted":true,"_uuid":"85c42387f7cbe1d864e6ecd78110d36543b49c94"},"cell_type":"markdown","source":"# &#128205; Data Pre-processing\n\n## What is Data Pre-pocessing?\nData preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues. Data preprocessing prepares raw data for further processing.\n> "},{"metadata":{"trusted":true,"_uuid":"552d8f6aa05052620464a652d2a381c266a2fd98"},"cell_type":"markdown","source":"# &#128205; 1. Checking Missing Data[](http://)"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"aad4b40423e626080316e9baf284b7ee75b64d08"},"cell_type":"code","source":"ESR.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e88bcff9f978e728a07d29bd99eee000ec0e3bcc"},"cell_type":"code","source":"ESR.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c59e74a086f2f41b14f793b599f0938cdab43704"},"cell_type":"code","source":"ESR.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"38ab208871375f43e6afced6a807f23a85468a68"},"cell_type":"code","source":"X = ESR.iloc[:,1:179].values\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1c4c72aceecdc35866aee2ec777a435abaf46fc3"},"cell_type":"code","source":"plt.subplot(511)\nplt.plot(X[1,:])\nplt.title('Classes')\nplt.ylabel('uV')\nplt.subplot(512)\nplt.plot(X[7,:])\nplt.subplot(513)\nplt.plot(X[12,:])\nplt.subplot(514)\nplt.plot(X[0,:])\nplt.subplot(515)\nplt.plot(X[2,:])\nplt.xlabel('Samples')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"32875b29c90672f90bdba34fcb94656dfce9fb70"},"cell_type":"code","source":"y = ESR.iloc[:,179].values\ny","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"182336e56e686533317d167bda1b5de60e3a3d14"},"cell_type":"markdown","source":"To make this a binary problem, let's turn the non-seizure classes 0 while maintaining the seizure as 1."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"67cdd58fc5bdc0fea9fff3a6c3eb030d17bb5fef"},"cell_type":"code","source":"y[y>1]=0\ny","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8f8bee91ce354f316e8ebb6d43f3a38d468c06e"},"cell_type":"markdown","source":"# &#128295; Building Machine Learning Models"},{"metadata":{"_uuid":"3935f14daec0df6ff948054196c77fdf6a8d9196"},"cell_type":"markdown","source":"##  Splitting the Dataset into the Training set and Test set\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nx = scaler.transform(X)\nfrom keras.utils import to_categorical\ny = to_categorical(y)\ny","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"98ca8b335764e01df2b8aaa10183a4e577854d30"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"215e46fbe236162ccd3f551bdd4f58c4e13f30fd"},"cell_type":"markdown","source":"## Feature Scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.reshape(x_train, (x_train.shape[0],1,X.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0],1,X.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\n\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM\ntf.keras.backend.clear_session()\n\nmodel = Sequential()\nmodel.add(LSTM(64, input_shape=(1,178),activation=\"relu\",return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32,activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\n#model.add(LSTM(100,return_sequences=True))\n#model.add(Dropout(0.2))\n#model.add(LSTM(50))\n#model.add(Dropout(0.2))\nmodel.add(Dense(2, activation='sigmoid'))\nfrom keras.optimizers import SGD\nmodel.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs = 100, validation_data= (x_test, y_test))\nscore, acc = model.evaluate(x_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\npred = model.predict(x_test)\npredict_classes = np.argmax(pred,axis=1)\nexpected_classes = np.argmax(y_test,axis=1)\nprint(expected_classes.shape)\nprint(predict_classes.shape)\ncorrect = accuracy_score(expected_classes,predict_classes)\nprint(f\"Training Accuracy: {correct}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}