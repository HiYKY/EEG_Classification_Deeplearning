{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Link to the dataset:**:[https://www.kaggle.com/harunshimanto/epileptic-seizure-recognition](https://www.kaggle.com/harunshimanto/epileptic-seizure-recognition)","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"> # &#128227; What is Epilespy\nEpilepsy is a serious brain illness that is an endemic neurological disorder all over  the world. It is a clinical result that occurs with abnormal neurological electrical  discharging of brain. Epileptic seizures represent the most common positive signs and  symptoms of brain disturbance, and epilepsy is one of the most common primary  brain disorders . Vascular causes, traumatic causes, infections and brain abscesses,  brain tumors, nutritional deficiencies, pyridoxine deficiency, calcium metabolism  disorders are lead causes for epilepsy. For in diagnosing epilepsy, research is needed  for better understanding of mechanisms causing epileptic disorders. The evaluation  and treatment of neurophysiologic disorders are diagnosed with the  electroencephalogram [EEG]. EEG is crucial for accurate classification of different  forms of epilepsy .","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Theoretical Background\nThe aim of this study is to contribute to the diagnosis of epilepsy by taking advantage of the engineering. So, for diagnosing of epileptic seizures from EEG signals are transformed discrete wavelet and auto regressive models. After these transformations, extract data is applied input for an LSTM","execution_count":null},{"metadata":{"_uuid":"f87ef7827d46d14e55f921b25c7d762175e941dc"},"cell_type":"markdown","source":"# EEG Data Recording\nEEG signals are separated into α, β, δ and θ spectral components and provide a  wide range of frequency components. EEG spectrum contains some characteristic  waveforms that fall primarily within four frequency bands as follows: δ(0.5-4 Hz),  θ(4-8 Hz), α(8-13 Hz), and β (13- 30 Hz) .\nEEG data set has acquired different age groups in this study. They are known  epileptic with uncontrolled seizures and are admitted to the neurology department of the Medical Faculty Hospital of Dicle University1. For this system LabView pro-  gramming language has been used  and the EEG data used in 400 people who re-  ceived 200 of them are epilepsy and with 200 of them are normal. Data set represents  of signals belong to several healthy and epileptic patients. The EEG signals that are  contained by PCI-MIO 16E DAQ card system that provides real time processing and  is a data bus of computer, signal processor and personal computer. Fig. 2 shows that  how to acquire EEG data from a patient [1]. EEG signals are to ensure the accuracy of  diagnosing disease that usually is taken 8-10 hours in the form of records. EEG sig-  nals are used in section and 23.6 seconds, 173 Hz sampling frequency is illustrated  with. International 10–20 electrode placement system according to the data collected,  12-bit analog-digital conversion after the samples are recorded subsequently. Data can  be passed through the filter 0.53–40 Hz band–pass, the EEG in the presence of clini-  cal interest for focusing range is provided. The EEG data used in our study were  downloaded from 24-h EEG recorded from both epileptic patients and normal sub-  jects. The following bipolar EEG channels were selected for analysis: F7-C3, F8-C4,  T5-O1 and T6-O2. In order to assess the performance of the classifier, we selected  500 EEG segments containing spike and wave complex, artifacts and background  normal EEG .\n![Imgur](https://i.imgur.com/6rQgYS9.png)","execution_count":null},{"metadata":{"trusted":true,"_uuid":"30e388d1b8ce7f8c9654828ef320fb39d953bab0"},"cell_type":"markdown","source":"# Discrete Wavelet Transform\nWavelet transform is more advantageous spectral analyze method than other  spectral analyze methods on non-stationary signals. Because the wavelet transform  method changes large low-frequency, high frequency that is narrow for the window  size. So, the entire frequency range can be achieved in the optimum time-frequency  resolution [22] Continuous and discrete wavelet transform is analyzed in the scale and  variation of parameters due to the continuous wavelet coefficients for each scale is  difficult and time consuming. For this reason, discrete wavelet transform is used more\nften than these non-stationary signals. Wavelet scale is divided into a number of  points for x[n] process as seen in Fig. 2 that is called multi resolution decomposition.  It is important that is selected appropriate wavelet decomposition level, the number of  detection and wavelet transform analysis of signals. Because of classification accura-  cy is dependent on type of wavelet, dominant frequency components of signals are  determined according to the number of decomposition levels.\nWavelet coefficients contain important information about EEG signal that provide  extraction of feature vector. Statistical-time frequency of EEG signals sequences are:\n\nThe average of the absolute value of coefficients in each sub-band.\nThe maximum absolute value of coefficients in each sub-band.\nThe mean force coefficients of each sub-band.\nStandard deviation of coefficients in each sub-band.\nThe average absolute value of the ratio of adjacent bands.\nDistribution of breakdown coefficients in each sub-band.\n\n1-3 sequence is signal characteristic; 4-6 sequence is that amount of frequency  change. This feature vector, of EEG signals that are used as inputs for multi-layer  neural network classification.\n![Imgur](https://i.imgur.com/Jzj3UAU.png)","execution_count":null},{"metadata":{"_uuid":"b9ad6f280e93376b5811f0cd1f25556150660b21"},"cell_type":"markdown","source":"# Importing the libraries","execution_count":null},{"metadata":{"trusted":true,"_uuid":"87d159a308dde25e6f89f58501552945f4c261cf","_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sn","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"710c7bc8e8f0ebf31b579ae609e2c8b364e4b731"},"cell_type":"markdown","source":"# Load the Dataset","execution_count":null},{"metadata":{"trusted":true,"_uuid":"ffb826c5e8da301b74c3a0161e7dcc079fec03ce","_kg_hide-input":true},"cell_type":"code","source":"ESR = pd.read_csv('../input/Epileptic Seizure Recognition.csv')\nESR.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f747e03448e282cdb4f5a611a8aa2191acc71c80"},"cell_type":"markdown","source":"# Read and Show Dataset\n* The original dataset from the reference consists of 5 different folders, each with 100 files, with each file representing a single subject/person. Each file is a recording of brain activity for 23.6 seconds.\n\n* The corresponding time-series is sampled into 4097 data points. Each data point is the value of the EEG recording at a different point in time. So we have total 500 individuals with each has 4097 data points for 23.5 seconds.\n\n* We divided and shuffled every 4097 data points into 23 chunks, each chunk contains 178 data points for 1 second, and each data point is the value of the EEG recording at a different point in time.\n\n* So now we have 23 x 500 = 11500 pieces of information(row), each information contains 178 data points for 1 second(column), the last column represents the label y {1,2,3,4,5}.\n\n* The response variable is y in column 179, the Explanatory variables X1, X2, ..., X178","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ESR.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98727073fd4a8acefbbe53251f25fe30986f1e2f","_kg_hide-input":true},"cell_type":"code","source":"ESR.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"17c90c1ff8add7ace30bd8d2cfb1fa5cb48c0e48"},"cell_type":"code","source":"cols = ESR.columns\ntgt = ESR.y\ntgt.unique()\ntgt[tgt>1]=0\nax = sn.countplot(tgt,label=\"Count\")\nnon_seizure, seizure = tgt.value_counts()\nprint('The number of trials for the non-seizure class is:', non_seizure)\nprint('The number of trials for the seizure class is:', seizure)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b8358047321392e0f1a2fb20ca53c6668d8cdf3"},"cell_type":"markdown","source":"As we can see, there are 178 EEG features and 5 possible classes. The main goal of the dataset it's to be able to correctly identify epileptic seizures from EEG data, so a binary classification between classes of label 1 and the rest (2,3,4,5). In order to train our model, let's define our independent variables (X) and our dependent variable (y).","execution_count":null},{"metadata":{"trusted":true,"_uuid":"85c42387f7cbe1d864e6ecd78110d36543b49c94"},"cell_type":"markdown","source":"# &#128205; Data Pre-processing\n\n## What is Data Pre-pocessing?\nData preprocessing is a data mining technique that involves transforming raw data into an understandable format. Real-world data is often incomplete, inconsistent, and/or lacking in certain behaviors or trends, and is likely to contain many errors. Data preprocessing is a proven method of resolving such issues. Data preprocessing prepares raw data for further processing.\n> ","execution_count":null},{"metadata":{"trusted":true,"_uuid":"552d8f6aa05052620464a652d2a381c266a2fd98"},"cell_type":"markdown","source":"# &#128205; 1. Checking Missing Data[](http://)","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"aad4b40423e626080316e9baf284b7ee75b64d08"},"cell_type":"code","source":"ESR.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab3a886cede2b110c7a6f5a28f42a15b478559e0"},"cell_type":"markdown","source":"# &#128205; Exploratory Data Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdaf9a18dd4802a74fda29c78b594fdea389e2b1"},"cell_type":"markdown","source":"## &#128505; What is Exploratory data analysis?\nIn statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.\n\nYou can say that EDA is statisticians way of story telling where you explore data, find patterns and tells insights. Often you have some questions in hand you try to validate those questions by performing EDA. <b>I have one article on [EDA](https://hackernoon.com/overview-of-exploratory-data-analysis-with-python-6213e105b00b)","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e88bcff9f978e728a07d29bd99eee000ec0e3bcc"},"cell_type":"code","source":"ESR.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c59e74a086f2f41b14f793b599f0938cdab43704"},"cell_type":"code","source":"ESR.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"38ab208871375f43e6afced6a807f23a85468a68"},"cell_type":"code","source":"X = ESR.iloc[:,1:179].values\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1c4c72aceecdc35866aee2ec777a435abaf46fc3"},"cell_type":"code","source":"plt.subplot(511)\nplt.plot(X[1,:])\nplt.title('Classes')\nplt.ylabel('uV')\nplt.subplot(512)\nplt.plot(X[7,:])\nplt.subplot(513)\nplt.plot(X[12,:])\nplt.subplot(514)\nplt.plot(X[0,:])\nplt.subplot(515)\nplt.plot(X[2,:])\nplt.xlabel('Samples')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"32875b29c90672f90bdba34fcb94656dfce9fb70"},"cell_type":"code","source":"y = ESR.iloc[:,179].values\ny","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"182336e56e686533317d167bda1b5de60e3a3d14"},"cell_type":"markdown","source":"To make this a binary problem, let's turn the non-seizure classes 0 while maintaining the seizure as 1.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"67cdd58fc5bdc0fea9fff3a6c3eb030d17bb5fef"},"cell_type":"code","source":"y[y>1]=0\ny","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8f8bee91ce354f316e8ebb6d43f3a38d468c06e"},"cell_type":"markdown","source":"# &#128295; Building Machine Learning Models","execution_count":null},{"metadata":{"_uuid":"3935f14daec0df6ff948054196c77fdf6a8d9196"},"cell_type":"markdown","source":"##  Splitting the Dataset into the Training set and Test set\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nx = scaler.transform(X)\nfrom keras.utils import to_categorical\ny = to_categorical(y)\ny","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"98ca8b335764e01df2b8aaa10183a4e577854d30"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, cross_val_score\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"215e46fbe236162ccd3f551bdd4f58c4e13f30fd"},"cell_type":"markdown","source":"## Feature Scaling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.reshape(x_train, (x_train.shape[0],1,X.shape[1]))\nx_test = np.reshape(x_test, (x_test.shape[0],1,X.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Sequential\n\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import LSTM\ntf.keras.backend.clear_session()\n\nmodel = Sequential()\nmodel.add(LSTM(64, input_shape=(1,178),activation=\"relu\",return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32,activation=\"sigmoid\"))\nmodel.add(Dropout(0.5))\n#model.add(LSTM(100,return_sequences=True))\n#model.add(Dropout(0.2))\n#model.add(LSTM(50))\n#model.add(Dropout(0.2))\nmodel.add(Dense(2, activation='sigmoid'))\nfrom keras.optimizers import SGD\nmodel.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs = 100, validation_data= (x_test, y_test))\nscore, acc = model.evaluate(x_test, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\npred = model.predict(x_test)\npredict_classes = np.argmax(pred,axis=1)\nexpected_classes = np.argmax(y_test,axis=1)\nprint(expected_classes.shape)\nprint(predict_classes.shape)\ncorrect = accuracy_score(expected_classes,predict_classes)\nprint(f\"Training Accuracy: {correct}\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}